name: Update Rules

on:
  workflow_dispatch: {}
  schedule:
    #- cron: "30 2 * * 1" # UTC 每天 02:30

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Append AD Rules
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Rules

          base_url="https://raw.githubusercontent.com/v2fly/domain-list-community/master/data"
          ad_file="Rules/AD Man.txt"

          # safe trim (pure bash) — 保留反斜杠，不调用 echo/xargs
          trim() {
            local var="$1"
            var="${var#"${var%%[![:space:]]*}"}"
            var="${var%"${var##*[![:space:]]}"}"
            printf '%s' "$var"
          }

          convert_list_to_rules() {
            local name="$1"
            local url="$base_url/$name"
            local tmp_file
            tmp_file="$(mktemp)"
            if ! curl -fsSL --connect-timeout 10 --max-time 60 "$url" -o "$tmp_file"; then
              echo "Warning: Failed to fetch $name" >&2
              rm -f "$tmp_file"
              return 0
            fi

            while IFS= read -r line; do
              raw="$line"
              line="${line%%#*}"
              line="$(trim "$line")"
              [ -z "$line" ] && continue

              # 去掉 @ 标签并再次 trim，防止尾部残留空格
              line="${line%%@*}"
              line="$(trim "$line")"

              if [[ "$line" == include:* ]]; then
                sub="$(trim "${line#include:}")"
                convert_list_to_rules "$sub"
              elif [[ "$line" == full:* ]]; then
                printf '%s\n' "  - DOMAIN,${line#full:}"
              elif [[ "$line" == domain:* ]]; then
                printf '%s\n' "  - DOMAIN-SUFFIX,${line#domain:}"
              elif [[ "$line" == keyword:* ]]; then
                printf '%s\n' "  - DOMAIN-KEYWORD,${line#keyword:}"
              elif [[ "$line" == DOMAIN-WILDCARD,* ]]; then
                printf '%s\n' "  - $line"
              elif [[ "$line" == regexp:* ]]; then
                printf '%s\n' "  - DOMAIN-REGEX,${line#regexp:}"
              elif [[ "$line" == regex:* ]]; then
                printf '%s\n' "  - DOMAIN-REGEX,${line#regex:}"
              else
                printf '%s\n' "  - DOMAIN-SUFFIX,$line"
              fi
            done < "$tmp_file"
            rm -f "$tmp_file"
          }

          echo "Updating AD rules in $ad_file (replace marker blocks if present)..."
          touch "$ad_file"

          for entry in category-httpdns-cn tencent-ads alibaba-ads sina-ads; do
            marker_start="### BEGIN AUTO $entry (do not edit)"
            marker_end="### END AUTO $entry"

            # 生成新块到临时文件（**不**在开头写入空行）
            tmp_block="$(mktemp)"
            printf '%s\n' "$marker_start" > "$tmp_block"
            printf '%s\n' "# Generated at: $(date '+%Y-%m-%d %H:%M %Z')" >> "$tmp_block"
            convert_list_to_rules "$entry" >> "$tmp_block"
            printf '%s\n' "$marker_end" >> "$tmp_block"

            # 如果原文件存在，移除旧的相同 marker 区块
            if [ -f "$ad_file" ]; then
              tmp_file="$(mktemp)"
              awk -v s="$marker_start" -v e="$marker_end" '
                $0==s {del=1; next}
                $0==e {del=0; next}
                !del {print}
              ' "$ad_file" > "$tmp_file"
              mv "$tmp_file" "$ad_file"
            fi

            # 在追加之前，确保文件与块之间只有一个换行分隔
            if [ ! -s "$ad_file" ]; then
              # 目标文件为空，直接追加
              cat "$tmp_block" >> "$ad_file"
            else
              # 检查最后一个字节是否为 '\n'
              last_char=$(tail -c 1 "$ad_file" || true)
              if [ "$last_char" != "" ] && [ "$last_char" != $'\n' ]; then
                printf '\n' >> "$ad_file"
              fi
              cat "$tmp_block" >> "$ad_file"
            fi

            rm -f "$tmp_block"
            echo "Updated $entry block in $ad_file"
          done

      - name: Download and Convert Domain Lists
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Rules/Auto

          base_url="https://raw.githubusercontent.com/v2fly/domain-list-community/master/data"

          declare -A entries=(
            ["google"]="Google.txt"
            ["apple-tvplus"]="AppleTV.txt"
            ["disney"]="DisneyPlus.txt"
            ["netflix"]="Netflix.txt"
            ["hbo"]="HBO.txt"
            ["tiktok"]="TikTok.txt"
            ["category-ai-!cn"]="AiSuite.txt"
            ["private"]="Private.txt"
          )

          trim() {
            local var="$1"
            var="${var#"${var%%[![:space:]]*}"}"
            var="${var%"${var##*[![:space:]]}"}"
            printf '%s' "$var"
          }

          fetch_and_parse() {
            local name="$1"
            local outfile="$2"

            if [[ -n "${visited[$name]+x}" ]]; then
              return
            fi
            visited[$name]=1

            local url="$base_url/$name"
            echo "Fetching $name ..."
            local tmp_file
            tmp_file="$(mktemp)"
            if ! curl -fsSL --connect-timeout 10 --max-time 60 "$url" -o "$tmp_file"; then
              echo "Warning: Failed to fetch $name" >&2
              rm -f "$tmp_file"
              return 0
            fi

            while IFS= read -r line; do
              raw="$line"
              line="${line%%#*}"
              line="$(trim "$line")"
              [ -z "$line" ] && continue

              # 去掉 @ 标签并再次 trim，防止尾部残留空格
              line="${line%%@*}"
              line="$(trim "$line")"

              if [[ "$line" == include:* ]]; then
                sub="$(trim "${line#include:}")"
                fetch_and_parse "$sub" "$outfile"
                continue
              fi

              if [[ "$line" == full:* ]]; then
                printf '%s\n' "  - DOMAIN,${line#full:}" >> "$outfile"
              elif [[ "$line" == domain:* ]]; then
                printf '%s\n' "  - DOMAIN-SUFFIX,${line#domain:}" >> "$outfile"
              elif [[ "$line" == keyword:* ]]; then
                printf '%s\n' "  - DOMAIN-KEYWORD,${line#keyword:}" >> "$outfile"
              elif [[ "$line" == DOMAIN-WILDCARD,* ]]; then
                printf '%s\n' "  - $line" >> "$outfile"
              elif [[ "$line" == regexp:* ]]; then
                printf '%s\n' "  - DOMAIN-REGEX,${line#regexp:}" >> "$outfile"
              elif [[ "$line" == regex:* ]]; then
                printf '%s\n' "  - DOMAIN-REGEX,${line#regex:}" >> "$outfile"
              else
                printf '%s\n' "  - DOMAIN-SUFFIX,$line" >> "$outfile"
              fi
            done < "$tmp_file"
            rm -f "$tmp_file"
          }

          for entry in "${!entries[@]}"; do
            outfile="Rules/Auto/${entries[$entry]}"
            printf '%s\n' "# Last update: $(date '+%Y-%m-%d %H:%M %Z')" > "$outfile"
            printf '%s\n' "payload:" >> "$outfile"
            declare -A visited=()
            fetch_and_parse "$entry" "$outfile"
            tmp="$(mktemp)"
            awk '!seen[$0]++' "$outfile" > "$tmp"
            mv "$tmp" "$outfile"
            echo "Saved $outfile"
          done

      - name: Download and Convert Apple & Microsoft
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Rules/Auto

          base_url="https://raw.githubusercontent.com/v2fly/domain-list-community/master/data"

          declare -A entries=(
            ["apple"]="Apple"
            ["microsoft"]="Microsoft"
          )

          trim() {
            local var="$1"
            var="${var#"${var%%[![:space:]]*}"}"
            var="${var%"${var##*[![:space:]]}"}"
            printf '%s' "$var"
          }

          fetch_and_parse_split() {
            local name="$1"
            local outfile_cn="$2"
            local outfile_global="$3"

            if [[ -n "${visited[$name]+x}" ]]; then
              return
            fi
            visited[$name]=1

            local url="$base_url/$name"
            echo "Fetching $name ..."
            local tmp_file
            tmp_file="$(mktemp)"
            if ! curl -fsSL --connect-timeout 10 --max-time 60 "$url" -o "$tmp_file"; then
              echo "Warning: Failed to fetch $name" >&2
              rm -f "$tmp_file"
              return 0
            fi

            while IFS= read -r line; do
              raw="$line"
              line="${line%%#*}"
              line="$(trim "$line")"
              [ -z "$line" ] && continue

              if [[ "$line" == include:* ]]; then
                sub="$(trim "${line#include:}")"
                fetch_and_parse_split "$sub" "$outfile_cn" "$outfile_global"
                continue
              fi

              # 判断是否带 @cn（使用 raw 判断原始标签）
              if [[ "$raw" == *@cn* ]]; then
                target="$outfile_cn"
              else
                target="$outfile_global"
              fi

              # 去掉 @ 标签并再次 trim，防止尾部残留空格
              line="${line%%@*}"
              line="$(trim "$line")"

              if [[ "$line" == full:* ]]; then
                printf '%s\n' "  - DOMAIN,${line#full:}" >> "$target"
              elif [[ "$line" == domain:* ]]; then
                printf '%s\n' "  - DOMAIN-SUFFIX,${line#domain:}" >> "$target"
              elif [[ "$line" == keyword:* ]]; then
                printf '%s\n' "  - DOMAIN-KEYWORD,${line#keyword:}" >> "$target"
              elif [[ "$line" == DOMAIN-WILDCARD,* ]]; then
                printf '%s\n' "  - $line" >> "$target"
              elif [[ "$line" == regexp:* ]]; then
                printf '%s\n' "  - DOMAIN-REGEX,${line#regexp:}" >> "$target"
              elif [[ "$line" == regex:* ]]; then
                printf '%s\n' "  - DOMAIN-REGEX,${line#regex:}" >> "$target"
              else
                printf '%s\n' "  - DOMAIN-SUFFIX,$line" >> "$target"
              fi
            done < "$tmp_file"
            rm -f "$tmp_file"
          }

          for entry in "${!entries[@]}"; do
            base_name="${entries[$entry]}"
            outfile_global="Rules/Auto/${base_name}.txt"
            outfile_cn="Rules/Auto/${base_name}CN.txt"

            printf '%s\n' "# Last update: $(date '+%Y-%m-%d %H:%M %Z')" > "$outfile_global"
            printf '%s\n' "payload:" >> "$outfile_global"
            printf '%s\n' "# Last update: $(date '+%Y-%m-%d %H:%M %Z')" > "$outfile_cn"
            printf '%s\n' "payload:" >> "$outfile_cn"

            declare -A visited=()
            fetch_and_parse_split "$entry" "$outfile_cn" "$outfile_global"

            for f in "$outfile_global" "$outfile_cn"; do
              tmp="$(mktemp)"
              awk '!seen[$0]++' "$f" > "$tmp"
              mv "$tmp" "$f"
              echo "Saved $f"
            done
          done

      - name: Download Rules into Rules/System
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Rules/System
          mkdir -p Stash/System

          urls=(
            "https://raw.githubusercontent.com/Loyalsoldier/clash-rules/release/proxy.txt"
            "https://raw.githubusercontent.com/Loyalsoldier/clash-rules/release/direct.txt"
            "https://raw.githubusercontent.com/Loyalsoldier/clash-rules/release/cncidr.txt"
          )

          for u in "${urls[@]}"; do
            name="$(basename "$u")"
            echo "Downloading $name from $u"
            if ! curl -fsSL --connect-timeout 10 --max-time 60 "$u" -o "Rules/System/$name.tmp"; then
              echo "Warning: Failed to download $u"
              continue
            fi

            filesize=$(stat -c%s "Rules/System/$name.tmp")
            if [ "$filesize" -gt 10485760 ]; then
              echo "Warning: File $name is too large ($filesize bytes), skipping"
              rm "Rules/System/$name.tmp"
              continue
            fi

            mv "Rules/System/$name.tmp" "Rules/System/$name"
            cp "Rules/System/$name" "Stash/System/$name"
            echo "Successfully downloaded and copied $name"
          done

      - name: Download Rules into Stash/Text
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Stash/Text

          urls=(
            "https://raw.githubusercontent.com/Loyalsoldier/surge-rules/release/proxy.txt"
            "https://raw.githubusercontent.com/Loyalsoldier/surge-rules/release/direct.txt"
          )

          for u in "${urls[@]}"; do
            name="$(basename "$u")"
            echo "Downloading $name from $u"
            if ! curl -fsSL --connect-timeout 10 --max-time 60 "$u" -o "Stash/Text/$name.tmp"; then
              echo "Warning: Failed to download $u"
              continue
            fi

            filesize=$(stat -c%s "Stash/Text/$name.tmp")
            if [ "$filesize" -gt 10485760 ]; then
              echo "Warning: File $name is too large ($filesize bytes), skipping"
              rm "Stash/Text/$name.tmp"
              continue
            fi

            mv "Stash/Text/$name.tmp" "Stash/Text/$name"
            echo "Successfully downloaded $name"
          done

      - name: Append HK Relay Rules
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Rules

          base_url="https://raw.githubusercontent.com/v2fly/domain-list-community/master/data"
          hk_file="Rules/HK Relay.txt"
          marker_start="### BEGIN AUTO HK Relay (do not edit)"
          marker_end="### END AUTO HK Relay"

          trim() {
            local var="$1"
            var="${var#"${var%%[![:space:]]*}"}"
            var="${var%"${var##*[![:space:]]}"}"
            printf '%s' "$var"
          }

          convert_list_to_rules() {
            local name="$1"
            local url="$base_url/$name"
            local tmp_file
            tmp_file="$(mktemp)"
            if ! curl -fsSL --connect-timeout 10 --max-time 60 "$url" -o "$tmp_file"; then
              echo "Warning: Failed to fetch $name" >&2
              rm -f "$tmp_file"
              return 0
            fi

            while IFS= read -r line; do
              raw="$line"
              line="${line%%#*}"
              line="$(trim "$line")"
              [ -z "$line" ] && continue

              # 去掉 @ 标签并再次 trim，防止尾部残留空格
              line="${line%%@*}"
              line="$(trim "$line")"

              if [[ "$line" == include:* ]]; then
                sub="$(trim "${line#include:}")"
                convert_list_to_rules "$sub"
              elif [[ "$line" == full:* ]]; then
                printf '%s\n' "  - DOMAIN,${line#full:}"
              elif [[ "$line" == domain:* ]]; then
                printf '%s\n' "  - DOMAIN-SUFFIX,${line#domain:}"
              elif [[ "$line" == keyword:* ]]; then
                printf '%s\n' "  - DOMAIN-KEYWORD,${line#keyword:}"
              elif [[ "$line" == DOMAIN-WILDCARD,* ]]; then
                printf '%s\n' "  - $line"
              elif [[ "$line" == regexp:* ]]; then
                printf '%s\n' "  - DOMAIN-REGEX,${line#regexp:}"
              elif [[ "$line" == regex:* ]]; then
                printf '%s\n' "  - DOMAIN-REGEX,${line#regex:}"
              else
                printf '%s\n' "  - DOMAIN-SUFFIX,$line"
              fi
            done < "$tmp_file"
            rm -f "$tmp_file"
          }

          echo "Updating HK Relay rules in $hk_file (replace marker block if present)..."
          touch "$hk_file"

          # 生成新的 HK Relay 块（不在开头写入多余空行）
          hk_tmp="$(mktemp)"
          printf '%s\n' "$marker_start" > "$hk_tmp"
          printf '%s\n' "# Generated at: $(date '+%Y-%m-%d %H:%M %Z')" >> "$hk_tmp"
          for entry in mytvsuper viu rthk now; do
            convert_list_to_rules "$entry" >> "$hk_tmp"
          done
          printf '%s\n' "$marker_end" >> "$hk_tmp"

          # 删除旧块（如果存在），再追加新块（保证只有单个换行分隔）
          if [ -f "$hk_file" ]; then
            tmp_file="$(mktemp)"
            awk -v s="$marker_start" -v e="$marker_end" '
              $0==s {del=1; next}
              $0==e {del=0; next}
              !del {print}
            ' "$hk_file" > "$tmp_file"
            mv "$tmp_file" "$hk_file"
          fi

          if [ ! -s "$hk_file" ]; then
            cat "$hk_tmp" >> "$hk_file"
          else
            last_char=$(tail -c 1 "$hk_file" || true)
            if [ "$last_char" != "" ] && [ "$last_char" != $'\n' ]; then
              printf '\n' >> "$hk_file"
            fi
            cat "$hk_tmp" >> "$hk_file"
          fi

          rm -f "$hk_tmp"
          echo "HK Relay rules updated in $hk_file"

      - name: Generate Rules/System/ChinaASN.txt from ASN-China
        shell: bash
        run: |
          set -euo pipefail
          URL="https://raw.githubusercontent.com/missuo/ASN-China/main/ASN.China.list"
          OUT="Rules/System/ChinaASN.txt"
          TMP="$(mktemp)"
          mkdir -p "$(dirname "$OUT")"

          echo "Downloading ASN-China list from $URL"
          if ! curl -fsSL --connect-timeout 10 --max-time 60 "$URL" -o "$TMP"; then
            echo "Warning: Failed to download ASN-China list"
            exit 1
          fi

          filesize=$(stat -c%s "$TMP")
          if [ "$filesize" -gt 5242880 ]; then
            echo "Warning: ASN-China list is too large ($filesize bytes), skipping processing"
            rm "$TMP"
            exit 1
          fi

          if ! grep -q "IP-ASN" "$TMP"; then
            echo "Warning: ASN-China list format seems invalid, skipping processing"
            head -n 10 "$TMP"
            rm "$TMP"
            exit 1
          fi

          {
            printf '%s\n' "payload:"
            sed 's/\r$//' "$TMP" \
              | sed 's/[[:space:]]*\/\/.*$//' \
              | grep -E '^[[:space:]]*IP-ASN,[0-9]+' \
              | awk '{print "  - " $0}'
          } > "$OUT"

          rm "$TMP"
          echo "Successfully generated ChinaASN.txt"

      - name: Prepare Stash copies (remove DOMAIN-REGEX lines and copy)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Stash Stash/Auto Stash/Text

          # Process Rules root files
          if [ -d "Rules" ]; then
            for src in Rules/*; do
              [ -f "$src" ] || continue
              dest="Stash/$(basename "$src")"
              # 只删除以两个空格 + "-" + " DOMAIN-REGEX," 开头的行，严格匹配
              sed '/^  - DOMAIN-REGEX,/d' "$src" > "$dest"
              echo "Prepared $dest (removed lines starting with '  - DOMAIN-REGEX,')"
            done
          fi

          # Process Rules/Auto files
          if [ -d "Rules/Auto" ]; then
            for src in Rules/Auto/*; do
              [ -f "$src" ] || continue
              dest="Stash/Auto/$(basename "$src")"
              sed '/^  - DOMAIN-REGEX,/d' "$src" > "$dest"
              echo "Prepared $dest (removed lines starting with '  - DOMAIN-REGEX,')"
            done
          fi

      - name: Force add new files
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git add -f Rules/** Stash/**

      - name: Commit & push if changed
        run: |
          if git diff --cached --quiet; then
            echo "No changes to commit."
          else
            git commit -m "Update Data"
            git push
          fi
