name: Update Rules

on:
  workflow_dispatch: {}
  schedule:
    - cron: "30 2 * * *" # UTC 每天 02:30

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Append AD Rules
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Rules

          base_url="https://raw.githubusercontent.com/v2fly/domain-list-community/master/data"
          ad_file="Rules/AD Man.txt"

          trim() { echo "$1" | xargs; }

          convert_list_to_rules() {
            local name="$1"
            local url="$base_url/$name"
            local tmp_file
            tmp_file="$(mktemp)"
            if ! curl -fsSL --connect-timeout 10 --max-time 60 "$url" -o "$tmp_file"; then
              echo "Warning: Failed to fetch $name" >&2
              return 0
            fi

            while IFS= read -r line; do
              line="${line%%#*}"
              line="$(trim "$line")"
              [ -z "$line" ] && continue
              line="${line%%@*}"

              if [[ "$line" == include:* ]]; then
                sub="$(trim "${line#include:}")"
                convert_list_to_rules "$sub"
              elif [[ "$line" == full:* ]]; then
                echo "  - DOMAIN,${line#full:}"
              elif [[ "$line" == domain:* ]]; then
                echo "  - DOMAIN-SUFFIX,${line#domain:}"
              elif [[ "$line" == keyword:* ]]; then
                echo "  - DOMAIN-KEYWORD,${line#keyword:}"
              elif [[ "$line" == DOMAIN-WILDCARD,* ]]; then
                echo "  - $line"
              elif [[ "$line" == regexp:* ]]; then
                # 保持原始的正则表达式，不做任何修改
                echo "  - DOMAIN-REGEX,${line#regexp:}"
              elif [[ "$line" == regex:* ]]; then
                # 保持原始的正则表达式，不做任何修改
                echo "  - DOMAIN-REGEX,${line#regex:}"
              else
                echo "  - DOMAIN-SUFFIX,$line"
              fi
            done < "$tmp_file"
          }

          echo "Updating AD rules in $ad_file (guarded by markers)..."
          touch "$ad_file"

          # 创建临时文件存储新内容
          tmp_ad_file="$(mktemp)"
          
          # 复制标记之前的内容（如果文件存在）
          if [[ -f "$ad_file" ]]; then
            marker_start="### BEGIN AUTO"
            # 如果找到标记，只保留标记之前的内容
            if grep -Fq "$marker_start" "$ad_file"; then
              sed "/$marker_start/,\$d" "$ad_file" > "$tmp_ad_file"
            else
              # 如果没有标记，保留整个文件
              cp "$ad_file" "$tmp_ad_file"
            fi
          fi

          # 添加所有自动生成的规则
          for entry in category-httpdns-cn google-ads baidu-ads umeng-ads adjust-ads tencent-ads alibaba-ads sina-ads; do
            marker_start="### BEGIN AUTO $entry (do not edit)"
            marker_end="### END AUTO $entry"

            {
              echo ""
              echo "$marker_start"
              echo "# Generated at: $(date '+%Y-%m-%d %H:%M %Z')"
              convert_list_to_rules "$entry"
              echo "$marker_end"
            } >> "$tmp_ad_file"
            echo "Updated $entry rules"
          done

          # 替换原文件
          mv "$tmp_ad_file" "$ad_file"
          echo "AD rules updated in $ad_file"

      - name: Download and Convert Domain Lists
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Rules/Auto

          base_url="https://raw.githubusercontent.com/v2fly/domain-list-community/master/data"

          declare -A entries=(
            ["google"]="Google.txt"
            ["apple-tvplus"]="AppleTV.txt"
            ["disney"]="DisneyPlus.txt"
            ["netflix"]="Netflix.txt"
            ["hbo"]="HBO.txt"
            ["tiktok"]="TikTok.txt"
            ["category-ai-!cn"]="AiSuite.txt"
            ["private"]="Private.txt"
          )

          trim() { echo "$1" | xargs; }

          fetch_and_parse() {
            local name="$1"
            local outfile="$2"

            if [[ -n "${visited[$name]+x}" ]]; then
              return
            fi
            visited[$name]=1

            local url="$base_url/$name"
            echo "Fetching $name ..."
            local tmp_file
            tmp_file="$(mktemp)"
            if ! curl -fsSL --connect-timeout 10 --max-time 60 "$url" -o "$tmp_file"; then
              echo "Warning: Failed to fetch $name" >&2
              return 0
            fi

            while IFS= read -r line; do
              line="${line%%#*}"
              line="$(trim "$line")"
              [ -z "$line" ] && continue
              line="${line%%@*}"

              if [[ "$line" == include:* ]]; then
                sub="$(trim "${line#include:}")"
                fetch_and_parse "$sub" "$outfile"
                continue
              fi

              if [[ "$line" == full:* ]]; then
                echo "  - DOMAIN,${line#full:}" >> "$outfile"
              elif [[ "$line" == domain:* ]]; then
                echo "  - DOMAIN-SUFFIX,${line#domain:}" >> "$outfile"
              elif [[ "$line" == keyword:* ]]; then
                echo "  - DOMAIN-KEYWORD,${line#keyword:}" >> "$outfile"
              elif [[ "$line" == DOMAIN-WILDCARD,* ]]; then
                echo "  - $line" >> "$outfile"
              elif [[ "$line" == regexp:* ]]; then
                # 保持原始的正则表达式
                echo "  - DOMAIN-REGEX,${line#regexp:}" >> "$outfile"
              elif [[ "$line" == regex:* ]]; then
                # 保持原始的正则表达式
                echo "  - DOMAIN-REGEX,${line#regex:}" >> "$outfile"
              else
                echo "  - DOMAIN-SUFFIX,$line" >> "$outfile"
              fi
            done < "$tmp_file"
          }

          for entry in "${!entries[@]}"; do
            outfile="Rules/Auto/${entries[$entry]}"
            echo "# Last update: $(date '+%Y-%m-%d %H:%M %Z')" > "$outfile"
            echo "payload:" >> "$outfile"
            declare -A visited=()
            fetch_and_parse "$entry" "$outfile"
            tmp="$(mktemp)"
            awk '!seen[$0]++' "$outfile" > "$tmp"
            mv "$tmp" "$outfile"
            echo "Saved $outfile"
          done

      - name: Download and Convert Apple & Microsoft
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Rules/Auto

          base_url="https://raw.githubusercontent.com/v2fly/domain-list-community/master/data"

          declare -A entries=(
            ["apple"]="Apple"
            ["microsoft"]="Microsoft"
          )

          trim() { echo "$1" | xargs; }

          fetch_and_parse_split() {
            local name="$1"
            local outfile_cn="$2"
            local outfile_global="$3"

            if [[ -n "${visited[$name]+x}" ]]; then
              return
            fi
            visited[$name]=1

            local url="$base_url/$name"
            echo "Fetching $name ..."
            local tmp_file
            tmp_file="$(mktemp)"
            if ! curl -fsSL --connect-timeout 10 --max-time 60 "$url" -o "$tmp_file"; then
              echo "Warning: Failed to fetch $name" >&2
              return 0
            fi

            while IFS= read -r line; do
              raw="$line"
              line="${line%%#*}"
              line="$(trim "$line")"
              [ -z "$line" ] && continue

              if [[ "$line" == include:* ]]; then
                sub="$(trim "${line#include:}")"
                fetch_and_parse_split "$sub" "$outfile_cn" "$outfile_global"
                continue
              fi

              if [[ "$raw" == *@cn* ]]; then
                target="$outfile_cn"
              else
                target="$outfile_global"
              fi

              line="${line%%@*}"

              if [[ "$line" == full:* ]]; then
                echo "  - DOMAIN,${line#full:}" >> "$target"
              elif [[ "$line" == domain:* ]]; then
                echo "  - DOMAIN-SUFFIX,${line#domain:}" >> "$target"
              elif [[ "$line" == keyword:* ]]; then
                echo "  - DOMAIN-KEYWORD,${line#keyword:}" >> "$target"
              elif [[ "$line" == DOMAIN-WILDCARD,* ]]; then
                echo "  - $line" >> "$target"
              elif [[ "$line" == regexp:* ]]; then
                # 保持原始的正则表达式
                echo "  - DOMAIN-REGEX,${line#regexp:}" >> "$target"
              elif [[ "$line" == regex:* ]]; then
                # 保持原始的正则表达式
                echo "  - DOMAIN-REGEX,${line#regex:}" >> "$target"
              else
                echo "  - DOMAIN-SUFFIX,$line" >> "$target"
              fi
            done < "$tmp_file"
          }

          for entry in "${!entries[@]}"; do
            base_name="${entries[$entry]}"
            outfile_global="Rules/Auto/${base_name}.txt"
            outfile_cn="Rules/Auto/${base_name}CN.txt"

            echo "# Last update: $(date '+%Y-%m-%d %H:%M %Z')" > "$outfile_global"
            echo "payload:" >> "$outfile_global"
            echo "# Last update: $(date '+%Y-%m-%d %H:%M %Z')" > "$outfile_cn"
            echo "payload:" >> "$outfile_cn"

            declare -A visited=()
            fetch_and_parse_split "$entry" "$outfile_cn" "$outfile_global"

            for f in "$outfile_global" "$outfile_cn"; do
              tmp="$(mktemp)"
              awk '!seen[$0]++' "$f" > "$tmp"
              mv "$tmp" "$f"
              echo "Saved $f"
            done
          done

      - name: Download Rules into Rules/System
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Rules/System

          urls=(
            "https://raw.githubusercontent.com/Loyalsoldier/clash-rules/release/proxy.txt"
            "https://raw.githubusercontent.com/Loyalsoldier/clash-rules/release/direct.txt"
            "https://raw.githubusercontent.com/Loyalsoldier/clash-rules/release/cncidr.txt"
          )

          for u in "${urls[@]}"; do
            name="$(basename "$u")"
            echo "Downloading $name from $u"
            if ! curl -fsSL --connect-timeout 10 --max-time 60 "$u" -o "Rules/System/$name.tmp"; then
              echo "Warning: Failed to download $u"
              continue
            fi

            filesize=$(stat -c%s "Rules/System/$name.tmp")
            if [ "$filesize" -gt 10485760 ]; then
              echo "Warning: File $name is too large ($filesize bytes), skipping"
              rm "Rules/System/$name.tmp"
              continue
            fi

            mv "Rules/System/$name.tmp" "Rules/System/$name"
            echo "Successfully downloaded $name"
          done

      - name: Download Rules into Rules/Text
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Rules/Text

          urls=(
            "https://raw.githubusercontent.com/Loyalsoldier/surge-rules/release/proxy.txt"
            "https://raw.githubusercontent.com/Loyalsoldier/surge-rules/release/direct.txt"
          )

          for u in "${urls[@]}"; do
            name="$(basename "$u")"
            echo "Downloading $name from $u"
            if ! curl -fsSL --connect-timeout 10 --max-time 60 "$u" -o "Rules/Text/$name.tmp"; then
              echo "Warning: Failed to download $u"
              continue
            fi

            filesize=$(stat -c%s "Rules/Text/$name.tmp")
            if [ "$filesize" -gt 10485760 ]; then
              echo "Warning: File $name is too large ($filesize bytes), skipping"
              rm "Rules/Text/$name.tmp"
              continue
            fi

            mv "Rules/Text/$name.tmp" "Rules/Text/$name"
            echo "Successfully downloaded $name"
          done

      - name: Append HK Relay Rules
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p Rules

          base_url="https://raw.githubusercontent.com/v2fly/domain-list-community/master/data"
          hk_file="Rules/HK Relay.txt"

          trim() { echo "$1" | xargs; }

          convert_list_to_rules() {
            local name="$1"
            local url="$base_url/$name"
            local tmp_file
            tmp_file="$(mktemp)"
            if ! curl -fsSL --connect-timeout 10 --max-time 60 "$url" -o "$tmp_file"; then
              echo "Warning: Failed to fetch $name" >&2
              return 0
            fi

            while IFS= read -r line; do
              line="${line%%#*}"
              line="$(trim "$line")"
              [ -z "$line" ] && continue
              line="${line%%@*}"

              if [[ "$line" == include:* ]]; then
                sub="$(trim "${line#include:}")"
                convert_list_to_rules "$sub"
              elif [[ "$line" == full:* ]]; then
                echo "  - DOMAIN,${line#full:}"
              elif [[ "$line" == domain:* ]]; then
                echo "  - DOMAIN-SUFFIX,${line#domain:}"
              elif [[ "$line" == keyword:* ]]; then
                echo "  - DOMAIN-KEYWORD,${line#keyword:}"
              elif [[ "$line" == DOMAIN-WILDCARD,* ]]; then
                echo "  - $line"
              elif [[ "$line" == regexp:* ]]; then
                # 保持原始的正则表达式
                echo "  - DOMAIN-REGEX,${line#regexp:}"
              elif [[ "$line" == regex:* ]]; then
                # 保持原始的正则表达式
                echo "  - DOMAIN-REGEX,${line#regex:}"
              else
                echo "  - DOMAIN-SUFFIX,$line"
              fi
            done < "$tmp_file"
          }

          echo "Updating HK Relay rules in $hk_file (guarded by markers)..."
          touch "$hk_file"

          # 创建临时文件存储新内容
          tmp_hk_file="$(mktemp)"
          
          # 复制标记之前的内容（如果文件存在）
          if [[ -f "$hk_file" ]]; then
            marker_start="### BEGIN AUTO HK Relay"
            # 如果找到标记，只保留标记之前的内容
            if grep -Fq "$marker_start" "$hk_file"; then
              sed "/$marker_start/,\$d" "$hk_file" > "$tmp_hk_file"
            else
              # 如果没有标记，保留整个文件
              cp "$hk_file" "$tmp_hk_file"
            fi
          fi

          # 添加自动生成的规则
          marker_start="### BEGIN AUTO HK Relay (do not edit)"
          marker_end="### END AUTO HK Relay"
          {
            echo ""
            echo "$marker_start"
            echo "# Generated at: $(date '+%Y-%m-%d %H:%M %Z')"
            for entry in mytvsuper viu rthk now; do
              convert_list_to_rules "$entry"
            done
            echo "$marker_end"
          } >> "$tmp_hk_file"

          # 替换原文件
          mv "$tmp_hk_file" "$hk_file"
          echo "HK Relay rules updated in $hk_file"

      - name: Generate Rules/System/ChinaASN.txt from ASN-China
        shell: bash
        run: |
          set -euo pipefail
          URL="https://raw.githubusercontent.com/missuo/ASN-China/main/ASN.China.list"
          OUT="Rules/System/ChinaASN.txt"
          TMP="$(mktemp)"
          mkdir -p "$(dirname "$OUT")"

          echo "Downloading ASN-China list from $URL"
          if ! curl -fsSL --connect-timeout 10 --max-time 60 "$URL" -o "$TMP"; then
            echo "Warning: Failed to download ASN-China list"
            exit 1
          fi

          filesize=$(stat -c%s "$TMP")
          if [ "$filesize" -gt 5242880 ]; then
            echo "Warning: ASN-China list is too large ($filesize bytes), skipping processing"
            rm "$TMP"
            exit 1
          fi

          if ! grep -q "IP-ASN" "$TMP"; then
            echo "Warning: ASN-China list format seems invalid, skipping processing"
            head -n 10 "$TMP"
            rm "$TMP"
            exit 1
          fi

          {
            echo "payload:"
            sed 's/\r$//' "$TMP" \
              | sed 's/[[:space:]]*\/\/.*$//' \
              | grep -E '^[[:space:]]*IP-ASN,[0-9]+' \
              | awk '{print "  - " $0}'
          } > "$OUT"

          rm "$TMP"
          echo "Successfully generated ChinaASN.txt"

      - name: Commit & push if changed
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update Data"
          file_pattern: Rules/**
